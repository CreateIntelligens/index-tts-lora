# =============================================================================
# Index-TTS LoRA 微調全域配置檔案
# 本檔案整合了資料處理工作流與模型訓練之參數設定
# =============================================================================

# === 工作流配置 (適用於資料準備與特徵提取階段) ===
workflow:
  # 路徑配置
  paths:
    data_source_dir: "data"                           # 原始音訊來源目錄
    audio_list_dir: "finetune_data/audio_list"         # 音訊列表 (Audio List) 輸出目錄
    processed_data_dir: "finetune_data/processed_data" # 特徵提取後的資料目錄
    log_dir: "logs"                                    # 執行日誌目錄

  # 資料準備 (Prepare) 配置
  prepare:
    split_size: 100000    # 自動分割大小 (每個分卷包含的行數)
                          # 建議值: 50000-100000 (數值越小分卷越多，適合多 GPU 平行處理)
                          # 設定為 0 則不進行分割

  # 特徵提取 (Extract) 配置
  extract:
    batch_size: 16        # 批次大小 (建議值: 16-64，請依據 GPU 視訊記憶體調整)
    num_workers: 8        # 資料載入執行緒數量 (建議值: 8-16)
    # GPU 配置 (可選)
    # gpus: "0,1,2,3"     # 指定使用的 GPU 裝置編號 (若留空或註解，預設使用 GPU 0-3)
                          # 範例: gpus: "4,5,6,7"  (使用 GPU 4-7)
                          # 範例: gpus: "0"        (僅使用 GPU 0)

  # Medoid 代表性樣本計算配置
  medoid:
    batch_size: 10000     # 單次計算的樣本行數 (建議值: 500-2000)
    chunk_size: 20000     # 列分塊大小 (建議值: 1000-3000)
                          # GPU 記憶體估算 ≈ batch_size × chunk_size × 4 bytes
                          # 範例: 1000 × 2000 ≈ 8MB (非常安全)
                          # 數值越大計算越快，但會消耗更多 GPU 記憶體

# === 模型架構配置 ===
dataset:
    bpe_model: bpe.model
    sample_rate: 24000
    squeeze: false
    mel:
        sample_rate: 24000
        n_fft: 1024
        hop_length: 256
        win_length: 1024
        n_mels: 100
        mel_fmin: 0
        normalize: false

gpt:
    model_dim: 1280
    max_mel_tokens: 800
    max_text_tokens: 600
    heads: 20
    use_mel_codes_as_input: true
    mel_length_compression: 1024
    layers: 24
    number_text_tokens: 12000
    number_mel_codes: 8194
    start_mel_token: 8192
    stop_mel_token: 8193
    start_text_token: 0
    stop_text_token: 1
    train_solo_embeddings: false
    condition_type: "conformer_perceiver"
    condition_module:
        output_size: 512
        linear_units: 2048
        attention_heads: 8
        num_blocks: 6
        input_layer: "conv2d2"
        perceiver_mult: 2

vqvae:
    channels: 100
    num_tokens: 8192
    hidden_dim: 512
    num_resnet_blocks: 3
    codebook_dim: 512
    num_layers: 2
    positional_dims: 1
    kernel_size: 3
    smooth_l1_loss: true
    use_transposed_convs: false

bigvgan:
    adam_b1: 0.8
    adam_b2: 0.99
    lr_decay: 0.999998
    seed: 1234

    resblock: "1"
    upsample_rates: [4, 4, 4, 4, 2, 2]
    upsample_kernel_sizes: [8, 8, 4, 4, 4, 4]
    upsample_initial_channel: 1536
    resblock_kernel_sizes: [3, 7, 11]
    resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
    feat_upsample: false
    speaker_embedding_dim: 512
    cond_d_vector_in_each_upsampling_layer: true

    gpt_dim: 1280

    activation: "snakebeta"
    snake_logscale: true

    use_cqtd_instead_of_mrd: true
    cqtd_filters: 128
    cqtd_max_filters: 1024
    cqtd_filters_scale: 1
    cqtd_dilations: [1, 2, 4]
    cqtd_hop_lengths: [512, 256, 256]
    cqtd_n_octaves: [9, 9, 9]
    cqtd_bins_per_octaves: [24, 36, 48]

    resolutions: [[1024, 120, 600], [2048, 240, 1200], [512, 50, 240]]
    mpd_reshapes: [2, 3, 5, 7, 11]
    use_spectral_norm: false
    discriminator_channel_mult: 1

    use_multiscale_melloss: true
    lambda_melloss: 15

    clip_grad_norm: 1000

    segment_size: 16384
    num_mels: 100
    num_freq: 1025
    n_fft: 1024
    hop_size: 256
    win_size: 1024

    sampling_rate: 24000

    fmin: 0
    fmax: null
    fmax_for_loss: null
    mel_type: "pytorch"

    num_workers: 2
    dist_config:
        dist_backend: "nccl"
        dist_url: "tcp://localhost:54321"
        world_size: 1

train:
    finetune_model_dir: "finetune_models" # 微調模型輸出根目錄
    seed: 91
    epochs: 15

    # === GPU 資源優化配置 ===
    # 注意：啟用動態條件 (Dynamic Conditioning) 會增加 Mel 頻譜輸入，
    # 導致視訊記憶體 (VRAM) 需求上升。建議適度降低批次大小以避免記憶體不足 (OOM)。
    batch_size: 128              # 單一 GPU 的訓練批次大小
    valid_batch_size: 256        # 單一 GPU 的驗證批次大小
    num_workers: 0              # 設定為 0 以避免 DDP 模式下的死鎖問題 (Deadlock)
    valid_num_workers: 0        # 設定為 0 以避免 DDP 模式下的死鎖問題
    prefetch_factor: null       # 當 num_workers=0 時必須設為 null
    persistent_workers: false   # 當 num_workers=0 時必須設為 false
    lazy_load_metadata: true    # 啟用完全延遲載入 (Lazy Loading)：僅在訓練時讀取檔案，不預先掃描 Metadata

    # =========================================================================
    # Cross-Speaker Conditioning 配置
    # =========================================================================
    # 訓練時以一定機率使用「其他說話人」的音檔作為 Conditioning 輸入。
    # 此策略強迫模型學習依賴 conditioning embedding 來區分說話人音色，
    # 避免 LoRA 層學會忽略參考音檔。
    #
    # 建議值:
    #   - 0.0  : 停用 (預設，僅使用同說話人不同音檔)
    #   - 0.15 : 15% 機率使用其他說話人 (建議起始值)
    #   - 0.2  : 20% 機率 (較強的約束)
    #
    # 注意: 比例過高可能影響收斂速度，建議從 0.15 開始測試。
    cross_speaker_ratio: 0.0

    # =========================================================================
    # Classifier-Free Guidance (CFG) 配置
    # =========================================================================
    # 訓練時以一定機率將 conditioning 設為零向量，強迫模型學習
    # 「有 conditioning」vs「無 conditioning」的差異。
    # 推理時可用 cfg_scale 放大 conditioning 的影響。
    #
    # 原理:
    #   - 訓練時 drop conditioning → 模型學會區分有/無 conditioning
    #   - 推理時: logits = uncond + scale * (cond - uncond)
    #   - 當 scale > 1.0 時，更強烈地依賴 conditioning
    #
    # 建議值:
    #   - 0.0  : 停用 CFG
    #   - 0.10 : 10% 機率 drop conditioning (保守)
    #   - 0.15 : 15% 機率 drop conditioning (建議起始值)
    #   - 0.20 : 20% 機率 drop conditioning (較強)
    #
    # 注意: CFG 與 cross_speaker 可以同時使用，但建議先單獨測試 CFG。
    cfg_dropout_ratio: 0.15

    # =========================================================================
    # 文字長度過濾與加權 (暫時停用以驗證模型架構)
    # =========================================================================
    # min_text_length: 5   # 最少文字長度（字數），過濾掉極短句（如：好、嗯）
    # max_text_length: 0   # 最大文字長度（字數），0 表示不限制
    #
    # # 文字長度加權取樣（降低短句出現機率，不刪除資料）
    # # 格式: {最大長度: 權重}，長度 > 最大 key 的句子權重為 1.0
    # text_length_weights:
    #   6: 0.3    # ≤6 字：權重 0.3（大幅降低）
    #   10: 0.7   # 7-10 字：權重 0.7（適度降低）
    #   # >10 字：權重 1.0（保持原樣）

    gradient_accumulation_steps: 16  # 梯度累積步數 (等效批次大小 ≈ batch_size * accumulation_steps)
    max_grad_norm: 1.0
    text_weight: 0.1
    early_stopping_patience: 1
    max_steps_per_epoch: 150    # 每個 Epoch 的最大訓練步數限制
    data_path: "finetune_data/processed_data/"

    # =========================================================================
    # 混合精度訓練配置 (PyTorch AMP)
    # =========================================================================
    # 說明: 
    #   前向/反向傳播使用低精度 (如 BF16/FP16) 以加速運算並節省記憶體。
    #   權重更新使用 FP32 以確保數值穩定性與準確性。
    #
    # 選項: "auto" | "bf16" | "fp16" | "fp8" | "fp32"
    #   - "auto" : 自動偵測硬體並選擇最佳精度 (推薦)
    #              (例如: H100 -> FP8, A100/RTX30/40 -> BF16, 舊款 GPU -> FP16)
    #   - "fp8"  : H100 專用，速度最快 (需 PyTorch 2.1+)
    #   - "bf16" : 適用於 A100/RTX30/40 系列，數值穩定性優於 FP16
    #   - "fp16" : 舊款 GPU 相容模式
    #   - "fp32" : 不使用混合精度 (速度較慢，但相容性最高)
    #
    mixed_precision: "auto"
    save_dtype: "bf16"       # 儲存模型精度 (選項: "fp32", "fp16", "bf16")

    optimizer:
        learning_rate: 5.0e-6
        weight_decay: 0.01
        warmup_ratio: 0.1       # 預熱 (Warmup) 步數佔總步數的比例
        loraplus_lr_ratio: 2.0  # LoRA+ B 矩陣的學習率倍率

    lora:
        r: 4
        lora_alpha: 8
        lora_dropout: 0.2
        target_modules:
            - "attn.c_attn"
            - "attn.c_proj"
            - "mlp.c_fc"
            - "mlp.c_proj"

dvae_checkpoint: dvae.pth
gpt_checkpoint: gpt.pth
bigvgan_checkpoint: bigvgan_generator.pth
version: 1.5

# =============================================================================
# 推理精度配置 (可選)
# =============================================================================
# 設定優先順序: config_inference.yaml > 此區塊 > is_fp16 參數
#
inference:
  gpt: "bf16"        # GPT 模型推理精度: bf16 | fp16 | fp32
  vocoder: "bf16"    # 聲碼器推理精度

  # Classifier-Free Guidance 推理配置
  # 需要先用 cfg_dropout_ratio > 0 訓練模型才有效
  cfg_scale: 1.0     # Guidance scale (1.0 = 不使用 CFG, >1.0 = 增強 conditioning)
                     # 建議範圍: 1.5 ~ 3.0

  quantization:      # 權重量化 (節省視訊記憶體)
    enabled: false
    weight_dtype: "int8"   # 權重類型: "int8" (節省 75% 顯存) | "int4" (節省 87.5% 顯存)
    compute_dtype: "bf16"  # 運算精度