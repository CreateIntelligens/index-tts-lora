# =============================================================================
# Index-TTS LoRA 微調統一配置文件
# 此文件整合了工作流配置和模型訓練配置
# =============================================================================

# === 工作流配置（prepare/extract 階段使用）===
workflow:
  # 路徑配置
  paths:
    data_source_dir: "data"                           # 原始音頻資料目錄
    audio_list_dir: "finetune_data/audio_list"         # audio_list 輸出目錄
    processed_data_dir: "finetune_data/processed_data" # 處理後的特徵資料目錄
    log_dir: "logs"                                    # 日誌目錄

  # Prepare 配置
  prepare:
    split_size: 100000    # 自動分割大小（每個 part 的行數）
                          # 建議: 50000-100000（數值越小，part 越多，適合更多 GPU）
                          # 設為 0 則不分割

  # Extract 配置
  extract:
    batch_size: 16        # 批次大小（建議: 16-64，根據 GPU 記憶體調整）
    num_workers: 8        # DataLoader worker 數量（建議: 8-16）
    # GPU 配置（可選）
    # gpus: "0,1,2,3"     # 指定使用的 GPU 編號（留空或註解則使用默認 GPU 0-3）
                          # 範例: gpus: "4,5,6,7"  (使用 GPU 4-7)
                          # 範例: gpus: "0"        (只用 GPU 0)

  # Medoid 計算配置
  medoid:
    batch_size: 10000     # 每次計算多少行（建議 500-2000）
    chunk_size: 20000     # 每個列分塊大小（建議 1000-3000）
                          # GPU 記憶體使用 ≈ batch_size × chunk_size × 4 bytes
                          # 例如 1000×2000 ≈ 8MB（很安全）
                          # 數值越大越快，但需要更多 GPU 記憶體

# === 模型配置 ===
dataset:
    bpe_model: bpe.model
    sample_rate: 24000
    squeeze: false
    mel:
        sample_rate: 24000
        n_fft: 1024
        hop_length: 256
        win_length: 1024
        n_mels: 100
        mel_fmin: 0
        normalize: false

gpt:
    model_dim: 1280
    max_mel_tokens: 800
    max_text_tokens: 600
    heads: 20
    use_mel_codes_as_input: true
    mel_length_compression: 1024
    layers: 24
    number_text_tokens: 12000
    number_mel_codes: 8194
    start_mel_token: 8192
    stop_mel_token: 8193
    start_text_token: 0
    stop_text_token: 1
    train_solo_embeddings: false
    condition_type: "conformer_perceiver"
    condition_module:
        output_size: 512
        linear_units: 2048
        attention_heads: 8
        num_blocks: 6
        input_layer: "conv2d2"
        perceiver_mult: 2

vqvae:
    channels: 100
    num_tokens: 8192
    hidden_dim: 512
    num_resnet_blocks: 3
    codebook_dim: 512
    num_layers: 2
    positional_dims: 1
    kernel_size: 3
    smooth_l1_loss: true
    use_transposed_convs: false

bigvgan:
    adam_b1: 0.8
    adam_b2: 0.99
    lr_decay: 0.999998
    seed: 1234

    resblock: "1"
    upsample_rates: [4, 4, 4, 4, 2, 2]
    upsample_kernel_sizes: [8, 8, 4, 4, 4, 4]
    upsample_initial_channel: 1536
    resblock_kernel_sizes: [3, 7, 11]
    resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
    feat_upsample: false
    speaker_embedding_dim: 512
    cond_d_vector_in_each_upsampling_layer: true

    gpt_dim: 1280

    activation: "snakebeta"
    snake_logscale: true

    use_cqtd_instead_of_mrd: true
    cqtd_filters: 128
    cqtd_max_filters: 1024
    cqtd_filters_scale: 1
    cqtd_dilations: [1, 2, 4]
    cqtd_hop_lengths: [512, 256, 256]
    cqtd_n_octaves: [9, 9, 9]
    cqtd_bins_per_octaves: [24, 36, 48]

    resolutions: [[1024, 120, 600], [2048, 240, 1200], [512, 50, 240]]
    mpd_reshapes: [2, 3, 5, 7, 11]
    use_spectral_norm: false
    discriminator_channel_mult: 1

    use_multiscale_melloss: true
    lambda_melloss: 15

    clip_grad_norm: 1000

    segment_size: 16384
    num_mels: 100
    num_freq: 1025
    n_fft: 1024
    hop_size: 256
    win_size: 1024

    sampling_rate: 24000

    fmin: 0
    fmax: null
    fmax_for_loss: null
    mel_type: "pytorch"

    num_workers: 2
    dist_config:
        dist_backend: "nccl"
        dist_url: "tcp://localhost:54321"
        world_size: 1

train:
    finetune_model_dir: "finetune_models" # 微調模型根目錄
    seed: 91
    epochs: 15

    # === GPU 使用率優化參數 - 針對 A100 80GB 優化 ===
    batch_size: 128             # 每 GPU 的 batch 大小
    valid_batch_size: 256       # 驗證批次
    num_workers: 0              # 設為 0 以防止 DDP 死鎖
    valid_num_workers: 0        # 設為 0 以防止 DDP 死鎖
    prefetch_factor: null       # num_workers=0 時必須為 null
    persistent_workers: false   # num_workers=0 時必須為 false
    lazy_load_metadata: true     # 真正的 lazy loading（不預先掃描，訓練時才讀檔案）

    gradient_accumulation_steps: 2  # 從 8 → 2，有效 batch = 64×2 = 128
    max_grad_norm: 1.0
    text_weight: 0.1
    early_stopping_patience: 1
    max_steps_per_epoch: 150 # 每個 epoch 最大訓練樣本數
    data_path: "finetune_data/processed_data/"

    # =========================================================================
    # 混合精度訓練 (PyTorch AMP)
    # =========================================================================
    # 說明: 前向/反向用低精度（快）→ 權重更新用 FP32（準）→ 自動完成
    #
    # 選項: "auto" | "bf16" | "fp16" | "fp8" | "fp32"
    #   - "auto" : 自動選擇（H100→FP8, A100/RTX30/40→BF16, 舊GPU→FP16）
    #   - "fp8"  : H100 專用，最快（需 PyTorch 2.1+）
    #   - "bf16" : A100/RTX30/40，穩定快速
    #   - "fp16" : 舊 GPU 兼容
    #   - "fp32" : 不使用混合精度（慢，任何 GPU 都可用）
    #
    mixed_precision: "auto"  # 推薦 auto，自動適應硬體

    optimizer:
        learning_rate: 5.0e-5
        weight_decay: 0.01
        warmup_ratio: 0.1 # 預熱步數佔總步數的比例
        loraplus_lr_ratio: 8.0 # LoRA+ B矩陣的學習率倍數

    lora:
        r: 16
        lora_alpha: 32
        lora_dropout: 0.1
        target_modules:
            - "attn.c_attn"
            - "attn.c_proj"
            - "mlp.c_fc"
            - "mlp.c_proj"

dvae_checkpoint: dvae.pth
gpt_checkpoint: gpt.pth
bigvgan_checkpoint: bigvgan_generator.pth
version: 1.5

# =============================================================================
# 推理精度配置（可選）
# =============================================================================
# 優先順序: config_inference.yaml > 此區塊 > is_fp16 參數
# 詳細說明請參考: PRECISION.md
#
inference:
  gpt: "bf16"        # bf16 | fp16 | fp32
  vocoder: "bf16"

  quantization:      # 省顯存模式
    enabled: false
    weight_dtype: "int8"   # int8（省75%）| int4（省87.5%）
    compute_dtype: "bf16"
