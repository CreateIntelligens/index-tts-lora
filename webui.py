import json
import os
import sys
import threading
import time
import pandas as pd
import argparse
import gradio as gr
import torch
import warnings

# éæ¿¾éå¿…è¦çš„è­¦å‘Šè¨Šæ¯
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# è¨­å®šå°ˆæ¡ˆè·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
sys.path.append(os.path.join(current_dir, "indextts"))

from indextts.infer import IndexTTS

# åƒæ•¸è§£æ
parser = argparse.ArgumentParser(description="IndexTTS WebUI - èªéŸ³åˆæˆç¶²é ä»‹é¢")
parser.add_argument("--verbose", action="store_true", default=False, help="å•Ÿç”¨è©³ç´°æ—¥èªŒæ¨¡å¼")
parser.add_argument("--port", type=int, default=7860, help="WebUI åŸ·è¡ŒåŸ è™Ÿ")
parser.add_argument("--host", type=str, default="127.0.0.1", help="WebUI ç›£è½ä½å€")
parser.add_argument("--model_dir", type=str, default="checkpoints", help="æ¨¡å‹æª¢æŸ¥é»ç›®éŒ„")
cmd_args = parser.parse_args()

# é©—è­‰æ¨¡å‹ç›®éŒ„èˆ‡å¿…è¦æª”æ¡ˆ
if not os.path.exists(cmd_args.model_dir):
    print(f"éŒ¯èª¤ï¼šæ¨¡å‹ç›®éŒ„ {cmd_args.model_dir} ä¸å­˜åœ¨ã€‚è«‹å…ˆä¸‹è¼‰æ¨¡å‹ã€‚")
    sys.exit(1)

required_files = [
    "bigvgan_generator.pth",
    "bpe.model",
    "gpt.pth",
    "config.yaml",
]

for file in required_files:
    file_path = os.path.join(cmd_args.model_dir, file)
    if not os.path.exists(file_path):
        print(f"éŒ¯èª¤ï¼šç¼ºå°‘å¿…è¦æª”æ¡ˆ {file_path}ã€‚è«‹ä¸‹è¼‰è©²æª”æ¡ˆã€‚")
        sys.exit(1)

# I18n æ¨¡çµ„ç›¸å®¹æ€§è™•ç†
try:
    from tools.i18n.i18n import I18nAuto
except ModuleNotFoundError:
    class I18nAuto:  # type: ignore
        """
        I18nAuto çš„ç°¡æ˜“æ›¿æ›é¡åˆ¥ï¼Œç”¨æ–¼åœ¨ç¼ºå°‘ tools æ¨¡çµ„æ™‚æä¾›åŸºæœ¬åŠŸèƒ½ã€‚
        """
        def __init__(self, language="zh_CN"):
            self.language = language

        def __call__(self, text: str) -> str:
            return text

        def __getattr__(self, name):
            # æ””æˆªæ‰€æœ‰æœªå®šç¾©å±¬æ€§çš„å­˜å–ï¼Œé˜²æ­¢ç¨‹å¼å´©æ½°
            return self

i18n = I18nAuto(language="zh_CN")
MODE = 'local'

# åˆå§‹åŒ– TTS å¼•æ“
tts = IndexTTS(model_dir=cmd_args.model_dir, cfg_path=os.path.join(cmd_args.model_dir, "config.yaml"))

os.makedirs("outputs/tasks", exist_ok=True)
os.makedirs("prompts", exist_ok=True)


def get_available_models() -> dict:
    """
    æƒæä¸¦å›å‚³æ‰€æœ‰å¯ç”¨çš„ GPT æ¨¡å‹æª¢æŸ¥é»ã€‚

    Returns:
        dict: éµç‚ºé¡¯ç¤ºåç¨±ï¼Œå€¼ç‚ºæª”æ¡ˆè·¯å¾‘çš„å­—å…¸ã€‚
    """
    models = {}

    # 1. é è¨­æ¨¡å‹
    default_model = os.path.join(cmd_args.model_dir, "gpt.pth")
    if os.path.exists(default_model):
        models["é è¨­æ¨¡å‹ (gpt.pth)"] = default_model

    # 2. å¾®èª¿å¾Œçš„æ¨¡å‹
    finetune_dir = "finetune_models/checkpoints"
    if os.path.exists(finetune_dir):
        # æ”¯æ´ .pth èˆ‡ .pt æ ¼å¼
        pth_files = sorted([
            f for f in os.listdir(finetune_dir) 
            if f.endswith('.pth')
        ])
        for pth_file in pth_files:
            display_name = f"è¨“ç·´æ¨¡å‹ - {pth_file}"
            full_path = os.path.join(finetune_dir, pth_file)
            models[display_name] = full_path

    return models


def reload_gpt_model(model_path: str, progress=gr.Progress()) -> str:
    """
    é‡æ–°è¼‰å…¥æŒ‡å®šçš„ GPT æ¨¡å‹æ¬Šé‡ã€‚

    Args:
        model_path (str): æ¨¡å‹æª”æ¡ˆè·¯å¾‘ã€‚
        progress (gr.Progress): Gradio é€²åº¦æ¢ç‰©ä»¶ã€‚

    Returns:
        str: æ“ä½œçµæœè¨Šæ¯ã€‚
    """
    global tts
    try:
        progress(0, desc="æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")

        from indextts.gpt.model import UnifiedVoice
        from indextts.utils.checkpoint import load_checkpoint
        
        # å»ºç«‹æ–°çš„æ¨¡å‹å¯¦ä¾‹
        new_gpt = UnifiedVoice(**tts.cfg.gpt)

        progress(0.3, desc="è¼‰å…¥æ¬Šé‡...")
        load_checkpoint(new_gpt, model_path)

        progress(0.6, desc="é…ç½®é‹ç®—è£ç½®èˆ‡ç²¾åº¦...")
        new_gpt = new_gpt.to(tts.device)
        
        # æ ¹æ“šå…¨åŸŸè¨­å®šé…ç½®ç²¾åº¦èˆ‡ DeepSpeed
        if tts.is_fp16:
            new_gpt.eval().half()
            try:
                import deepspeed
                use_deepspeed = True
            except ImportError:
                use_deepspeed = False
            new_gpt.post_init_gpt2_config(use_deepspeed=use_deepspeed, kv_cache=True, half=True)
        else:
            new_gpt.eval()
            new_gpt.post_init_gpt2_config(use_deepspeed=False, kv_cache=True, half=False)

        progress(0.9, desc="åˆ‡æ›æ¨¡å‹å¯¦ä¾‹...")
        
        # é‡‹æ”¾èˆŠæ¨¡å‹è¨˜æ†¶é«”
        del tts.gpt
        import gc
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        # æ›¿æ›ç‚ºæ–°æ¨¡å‹
        tts.gpt = new_gpt
        tts.gpt_path = model_path

        progress(1.0, desc="å®Œæˆ")
        return f"âœ… æˆåŠŸè¼‰å…¥æ¨¡å‹: {os.path.basename(model_path)}"

    except Exception as e:
        return f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"


available_models = get_available_models()

# è¼‰å…¥ç¯„ä¾‹æ¸¬è©¦æ¡ˆä¾‹
example_cases = []
try:
    with open("tests/cases.jsonl", "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            example = json.loads(line)
            example_cases.append([
                os.path.join("tests", example.get("prompt_audio", "sample_prompt.wav")),
                example.get("text"), 
                ["æ™®é€šæ¨ç†", "æ‰¹æ¬¡æ¨ç†"][example.get("infer_mode", 0)]
            ])
except FileNotFoundError:
    pass


def gen_single(prompt, text, infer_mode, max_text_tokens_per_sentence=120, sentences_bucket_max_size=4,
                *args, progress=gr.Progress()):
    """
    åŸ·è¡Œå–®æ¬¡èªéŸ³ç”Ÿæˆä»»å‹™ã€‚
    """
    output_path = os.path.join("outputs", f"spk_{int(time.time())}.wav")
    
    # è¨­å®š Gradio é€²åº¦å›èª¿
    tts.gr_progress = progress
    
    do_sample, top_p, top_k, temperature, \
        length_penalty, num_beams, repetition_penalty, max_mel_tokens = args
        
    kwargs = {
        "do_sample": bool(do_sample),
        "top_p": float(top_p),
        "top_k": int(top_k) if int(top_k) > 0 else None,
        "temperature": float(temperature),
        "length_penalty": float(length_penalty),
        "num_beams": num_beams,
        "repetition_penalty": float(repetition_penalty),
        "max_mel_tokens": int(max_mel_tokens),
    }

    if infer_mode == "æ™®é€šæ¨ç†":
        output = tts.infer(
            prompt, text, output_path, 
            verbose=cmd_args.verbose,
            max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
            **kwargs
        )
    else:
        # æ‰¹æ¬¡æ¨ç†æ¨¡å¼
        output = tts.infer_fast(
            prompt, text, output_path, 
            verbose=cmd_args.verbose,
            max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
            sentences_bucket_max_size=(sentences_bucket_max_size),
            **kwargs
        )
    return gr.update(value=output, visible=True)


def update_prompt_audio():
    return gr.update(interactive=True)


# å»ºæ§‹ Gradio ä»‹é¢
with gr.Blocks(title="IndexTTS Demo") as demo:
    mutex = threading.Lock()
    gr.HTML('''
    <h2><center>IndexTTS: å·¥æ¥­ç´šé«˜æ•ˆé›¶æ¨£æœ¬æ–‡å­—è½‰èªéŸ³ç³»çµ±</center></h2>
    <p align="center">
        <a href='https://arxiv.org/abs/2502.05512'><img src='https://img.shields.io/badge/ArXiv-2502.05512-red'></a>
    </p>
    ''')

    # æ¨¡å‹é¸æ“‡å€åŸŸ
    with gr.Accordion("ğŸ¯ æ¨¡å‹é¸æ“‡", open=True):
        with gr.Row():
            model_choices = list(available_models.keys())
            default_choice = model_choices[0] if model_choices else None

            model_dropdown = gr.Dropdown(
                choices=model_choices,
                value=default_choice,
                label="é¸æ“‡ GPT æ¨¡å‹",
                info=f"ç•¶å‰å·²è¼‰å…¥: {os.path.basename(tts.gpt_path)}"
            )

            reload_button = gr.Button("ğŸ”„ è¼‰å…¥æ¨¡å‹", variant="primary")
            refresh_button = gr.Button("ğŸ” é‡æ–°æƒæ", variant="secondary")

        def on_reload_model(selected_model, progress=gr.Progress()):
            if selected_model not in available_models:
                gr.Warning("ç„¡æ•ˆçš„æ¨¡å‹é¸æ“‡")
                return gr.update()
            model_path = available_models[selected_model]
            result = reload_gpt_model(model_path, progress)
            new_info = f"ç•¶å‰å·²è¼‰å…¥: {os.path.basename(tts.gpt_path)}"
            if "æˆåŠŸ" in result:
                gr.Info(result)
            else:
                gr.Warning(result)
            return gr.update(info=new_info)

        def on_refresh_models():
            global available_models
            available_models = get_available_models()
            new_choices = list(available_models.keys())
            gr.Info(f"æƒæå®Œæˆï¼Œæ‰¾åˆ° {len(new_choices)} å€‹æ¨¡å‹")
            return gr.update(choices=new_choices, value=new_choices[0] if new_choices else None)

        reload_button.click(
            on_reload_model,
            inputs=[model_dropdown],
            outputs=[model_dropdown]
        )

        refresh_button.click(
            on_refresh_models,
            inputs=[],
            outputs=[model_dropdown]
        )

    with gr.Tab("éŸ³è¨Šç”Ÿæˆ"):
        with gr.Row():
            os.makedirs("prompts", exist_ok=True)
            prompt_audio = gr.Audio(label="åƒè€ƒéŸ³è¨Š", key="prompt_audio",
                                    sources=["upload", "microphone"], type="filepath")
            
            with gr.Column():
                input_text_single = gr.TextArea(
                    label="æ–‡å­—è¼¸å…¥",
                    key="input_text_single", 
                    placeholder="è«‹è¼¸å…¥ç›®æ¨™æ–‡å­—", 
                    info=f"ç•¶å‰æ¨¡å‹ç‰ˆæœ¬: {tts.model_version or '1.0'}"
                )
                infer_mode = gr.Radio(
                    choices=["æ™®é€šæ¨ç†", "æ‰¹æ¬¡æ¨ç†"], 
                    label="æ¨ç†æ¨¡å¼",
                    info="æ‰¹æ¬¡æ¨ç†ï¼šæ›´é©åˆé•·å¥ï¼Œæ•ˆèƒ½è¼ƒé«˜",
                    value="æ™®é€šæ¨ç†"
                )        
                gen_button = gr.Button("ç”ŸæˆèªéŸ³", key="gen_button", interactive=True)
            output_audio = gr.Audio(label="ç”Ÿæˆçµæœ", visible=True, key="output_audio")
        
        with gr.Accordion("é€²éšç”Ÿæˆåƒæ•¸è¨­å®š", open=False):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("**GPT2 å–æ¨£è¨­å®š**\nåƒæ•¸æœƒå½±éŸ¿éŸ³è¨Šå¤šæ¨£æ€§å’Œç”Ÿæˆé€Ÿåº¦ã€‚")
                    with gr.Row():
                        do_sample = gr.Checkbox(label="å•Ÿç”¨å–æ¨£ (Do Sample)", value=True, info="æ˜¯å¦é€²è¡Œéš¨æ©Ÿå–æ¨£")
                        temperature = gr.Slider(label="æº«åº¦ (Temperature)", minimum=0.1, maximum=2.0, value=1.0, step=0.1)
                    with gr.Row():
                        top_p = gr.Slider(label="Top-P", minimum=0.0, maximum=1.0, value=0.8, step=0.01)
                        top_k = gr.Slider(label="Top-K", minimum=0, maximum=100, value=30, step=1)
                        num_beams = gr.Slider(label="Beam Search æ•¸é‡", value=3, minimum=1, maximum=10, step=1)
                    with gr.Row():
                        repetition_penalty = gr.Number(label="é‡è¤‡æ‡²ç½° (Repetition Penalty)", value=10.0, minimum=0.1, maximum=20.0, step=0.1)
                        length_penalty = gr.Number(label="é•·åº¦æ‡²ç½° (Length Penalty)", value=0.0, minimum=-2.0, maximum=2.0, step=0.1)
                    max_mel_tokens = gr.Slider(
                        label="æœ€å¤§ Mel Token æ•¸", 
                        value=600, 
                        minimum=50, 
                        maximum=tts.cfg.gpt.max_mel_tokens, 
                        step=10, 
                        info="ç”Ÿæˆ Token æœ€å¤§æ•¸é‡ï¼Œéå°æœƒå°è‡´éŸ³è¨Šè¢«æˆªæ–·", 
                        key="max_mel_tokens"
                    )

                with gr.Column(scale=2):
                    gr.Markdown("**åˆ†å¥è¨­å®š**\nå½±éŸ¿éŸ³è¨Šå“è³ªèˆ‡ç”Ÿæˆæ•ˆç‡ã€‚")
                    with gr.Row():
                        max_text_tokens_per_sentence = gr.Slider(
                            label="åˆ†å¥æœ€å¤§ Token æ•¸", 
                            value=120, minimum=20, maximum=tts.cfg.gpt.max_text_tokens, step=2, 
                            key="max_text_tokens_per_sentence",
                            info="å»ºè­° 80~200ã€‚å€¼è¶Šå¤§åˆ†å¥è¶Šé•·ï¼›å€¼è¶Šå°åˆ†å¥è¶Šç¢ã€‚"
                        )
                        sentences_bucket_max_size = gr.Slider(
                            label="åˆ†å¥åˆ†æ¡¶å®¹é‡ (æ‰¹æ¬¡æ¨ç†)", 
                            value=4, minimum=1, maximum=16, step=1, 
                            key="sentences_bucket_max_size",
                            info="å»ºè­° 2-8ã€‚å€¼è¶Šå¤§æ‰¹æ¬¡è™•ç†çš„åˆ†å¥æ•¸è¶Šå¤šï¼Œä½†è¨˜æ†¶é«”æ¶ˆè€—è¼ƒå¤§ã€‚"
                        )
                    with gr.Accordion("åˆ†å¥çµæœé è¦½", open=True):
                        sentences_preview = gr.Dataframe(
                            headers=["åºè™Ÿ", "åˆ†å¥å…§å®¹", "Tokenæ•¸"],
                            key="sentences_preview",
                            wrap=True,
                        )
            
            advanced_params = [
                do_sample, top_p, top_k, temperature,
                length_penalty, num_beams, repetition_penalty, max_mel_tokens,
            ]
        
        if len(example_cases) > 0:
            gr.Examples(
                examples=example_cases,
                inputs=[prompt_audio, input_text_single, infer_mode],
            )

    def on_input_text_change(text, max_tokens_per_sentence):
        if text and len(text) > 0:
            text_tokens_list = tts.tokenizer.tokenize(text)
            sentences = tts.tokenizer.split_sentences(
                text_tokens_list, 
                max_tokens_per_sentence=int(max_tokens_per_sentence)
            )
            data = []
            for i, s in enumerate(sentences):
                sentence_str = ''.join(s)
                tokens_count = len(s)
                data.append([i, sentence_str, tokens_count])
            
            return {
                sentences_preview: gr.update(value=data, visible=True, type="array"),
            }
        else:
            df = pd.DataFrame([], columns=["åºè™Ÿ", "åˆ†å¥å…§å®¹", "Tokenæ•¸"])
            return {
                sentences_preview: gr.update(value=df)
            }

    # äº‹ä»¶ç¶å®š
    input_text_single.change(
        on_input_text_change,
        inputs=[input_text_single, max_text_tokens_per_sentence],
        outputs=[sentences_preview]
    )
    max_text_tokens_per_sentence.change(
        on_input_text_change,
        inputs=[input_text_single, max_text_tokens_per_sentence],
        outputs=[sentences_preview]
    )
    prompt_audio.upload(
        update_prompt_audio,
        inputs=[],
        outputs=[gen_button]
    )

    gen_button.click(
        gen_single,
        inputs=[
            prompt_audio, input_text_single, infer_mode,
            max_text_tokens_per_sentence, sentences_bucket_max_size,
            *advanced_params,
        ],
        outputs=[output_audio]
    )

if __name__ == "__main__":
    demo.queue(20)
    demo.launch(server_name=cmd_args.host, server_port=cmd_args.port)
