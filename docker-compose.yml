services:
  index-tts-lora:
    build:
      context: .
      dockerfile: Dockerfile
    image: index-tts-lora:latest
    container_name: index-tts-lora

    # GPU 支援
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # 環境變數
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=4,5,6,7  # 多卡主機可取消註解並指定 GPU
      - UID=${UID:-1000}
      - GID=${GID:-1000}
      - USERNAME=${USER:-user}

    # 使用當前用戶運行 (避免 root 權限問題)
    # 暫時註解掉，等修復權限問題後再啟用
    # user: "${UID:-1000}:${GID:-1000}"

    # 端口映射
    ports:
      - "7860:7860"  # webui
      - "7859:7859"  # api.py
      - "7859:7859"  # API Port

    # 掛載卷 - 掛載整個專案目錄
    volumes:
      - .:/workspace/index-tts-lora
      # for p5
      - /mnt/data/output:/workspace/index-tts-lora/data
      # for A4000
      # - /mnt/nas/ml-material/segment_data/output/:/workspace/index-tts-lora/data

    working_dir: /workspace/index-tts-lora

    # 共享內存大小（DataLoader 多進程需要）
    shm_size: '128gb'

    # 同時啟動 API (7859) 和 WebUI (7860)
    command: bash scripts/start_all.sh

    # 自動重啟策略（包含健康檢查失敗時）
    restart: unless-stopped

    # NVIDIA GPU 健康檢查（暫時停用）
    # healthcheck:
    #   test: ["CMD-SHELL", "/bin/bash /gpu-healthcheck.sh"]
    #   interval: 30s
    #   timeout: 5s
    #   retries: 2
    #   start_period: 40s
