#!/bin/bash

# è¨“ç·´æ¨¡å‹è…³æœ¬

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/lib_common.sh"

train_model() {
    print_header "é–‹å§‹è¨“ç·´æ¨¡å‹"

    local mode="auto"  # auto, ddp, dp
    local num_gpus=""

    while [ $# -gt 0 ]; do
        case "$1" in
            --ddp)
                mode="ddp"
                ;;
            --dp)
                mode="dp"
                ;;
            --gpus)
                shift
                num_gpus="$1"
                ;;
            *)
                print_warning "æœªçŸ¥åƒæ•¸: $1"
                ;;
        esac
        shift
    done

    check_container

    # å»ºç«‹ log ç›®éŒ„
    LOG_DIR="logs/train_$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$LOG_DIR"
    LOG_FILE="$LOG_DIR/train.log"
    print_info "è¨“ç·´ log å°‡å„²å­˜è‡³: $LOG_FILE"

    # è‡ªå‹•æª¢æ¸¬ GPU æ•¸é‡ï¼ˆä½¿ç”¨ PyTorchï¼Œå°Šé‡ CUDA_VISIBLE_DEVICESï¼‰
    if [ -z "$num_gpus" ]; then
        if [ "$USE_DOCKER" -eq 1 ]; then
            num_gpus=$(docker compose exec index-tts-lora python3 -c "import torch; print(torch.cuda.device_count())" 2>/dev/null)
        else
            num_gpus=$(python3 -c "import torch; print(torch.cuda.device_count())" 2>/dev/null)
        fi

        if [ -z "$num_gpus" ] || [ "$num_gpus" -eq 0 ]; then
            print_error "æ‰¾ä¸åˆ°å¯ç”¨çš„ GPU"
            exit 1
        fi
    fi

    # è‡ªå‹•é¸æ“‡è¨“ç·´æ¨¡å¼
    if [ "$mode" = "auto" ]; then
        if [ "$num_gpus" -gt 1 ]; then
            mode="ddp"
            print_info "ğŸš€ æª¢æ¸¬åˆ° $num_gpus å€‹ GPUï¼Œè‡ªå‹•ä½¿ç”¨ DDP è¨“ç·´"
        else
            mode="dp"
            print_info "ğŸ“Œ æª¢æ¸¬åˆ° $num_gpus å€‹ GPUï¼Œä½¿ç”¨ DataParallel è¨“ç·´"
        fi
    fi

    if [ "$mode" = "ddp" ]; then
        print_info "ä½¿ç”¨ DDP è¨“ç·´ï¼ŒGPU æ•¸é‡: $num_gpus"

        if [ "$USE_DOCKER" -eq 1 ]; then
            docker compose exec index-tts-lora \
                python3 -m torch.distributed.run \
                --nproc_per_node="$num_gpus" \
                train_ddp.py 2>&1 | tee "$LOG_FILE"
        else
            python3 -m torch.distributed.run \
                --nproc_per_node="$num_gpus" \
                train_ddp.py 2>&1 | tee "$LOG_FILE"
        fi
    else
        print_info "ä½¿ç”¨ DataParallel è¨“ç·´"

        if [ "$USE_DOCKER" -eq 1 ]; then
            docker compose exec index-tts-lora python3 train.py 2>&1 | tee "$LOG_FILE"
        else
            python3 train.py 2>&1 | tee "$LOG_FILE"
        fi
    fi

    # ä¿®å¾© log æª”æ¡ˆæ¬Šé™
    if [ -f "$LOG_FILE" ]; then
        # å–å¾—å®¿ä¸»æ©Ÿç”¨æˆ¶ UID/GID
        HOST_UID=$(stat -c '%u' docker-compose.yml 2>/dev/null || echo "1000")
        HOST_GID=$(stat -c '%g' docker-compose.yml 2>/dev/null || echo "1000")
        chown $HOST_UID:$HOST_GID "$LOG_FILE" 2>/dev/null || true
        chown $HOST_UID:$HOST_GID "$LOG_DIR" 2>/dev/null || true
    fi

    if [ $? -eq 0 ]; then
        print_success "è¨“ç·´å®Œæˆï¼"
        print_info "Log æª”æ¡ˆ: $LOG_FILE"
    else
        print_error "è¨“ç·´å¤±æ•—ï¼"
        print_info "Log æª”æ¡ˆ: $LOG_FILE"
        exit 1
    fi
}

# ç›´æ¥åŸ·è¡Œæ™‚èª¿ç”¨
if [ "${BASH_SOURCE[0]}" == "${0}" ]; then
    train_model "$@"
fi
